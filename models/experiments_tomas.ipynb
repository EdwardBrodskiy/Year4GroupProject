{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from utils import load_everything\n",
    "#from validation import plot_confusion_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbdbb78-0abd-432f-bc9e-cbfc50dc758b",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset contains all of the metadata test and train sets are self explanatory \n",
    "# no shuffling is required this is all done in the loader. indexes match between the dataset and x_train etc\n",
    "# to index for the test set do dataset[len(x_train):]\n",
    "dataset, (x_train, x_test, y_train, y_test) = load_everything(os.path.join('..', 'datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1537e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd5e7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7785a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if it's within [0, 1] range\n",
    "print(f'x_train: max({x_train.max()}), min({x_train.min()})\\nx_test:  max({x_test.max()}), min({x_test.min()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca3625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_stats = pd.concat([\n",
    "        dataset['fire'].value_counts(),\n",
    "        dataset['fire'].value_counts(normalize=True)\n",
    "    ],\n",
    "    keys=['counts', 'normalized_counts'],\n",
    "    axis=1,\n",
    ")\n",
    "print(label_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc1a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_image_samples(dataset):\n",
    "    labels = np.unique(dataset['fire'])\n",
    "    fig, axs = plt.subplots(1, len(labels))\n",
    "    fig.set_size_inches(10,5)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for ax, label in zip(axs, labels):\n",
    "        img_sample = dataset[dataset['fire'] == label].sample(1)\n",
    "        img_name = f'{img_sample[\"img_name\"].iloc[0]}.jpg'\n",
    "        img_path = os.path.join(dataset_base_path, img_name)\n",
    "        img = plt.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(label)\n",
    "\n",
    "dataset_base_path = os.path.join('../datasets', 'generated')\n",
    "show_image_samples(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec371e",
   "metadata": {},
   "source": [
    "## Fitting a model to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1096395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d953ee",
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     12,
     18
    ]
   },
   "outputs": [],
   "source": [
    "def get_input_shape(data):\n",
    "    _, *input_shape = data.shape\n",
    "    return input_shape\n",
    "\n",
    "def reshape_data(data, base_size):\n",
    "    reshaped = [cv2.resize(img, base_size) for img in data]\n",
    "    return np.array(reshaped)\n",
    "\n",
    "def standardise(*data):\n",
    "    data = [d / 255.0 for d in data]\n",
    "    return data\n",
    "\n",
    "def add_seq_layers(layers):\n",
    "    model = models.Sequential([\n",
    "        *layers\n",
    "    ])\n",
    "    return model\n",
    "            \n",
    "def plot_model_history(history):\n",
    "    plt.figure(1, figsize = (15,8)) \n",
    "    plt.subplot(221)  \n",
    "    plt.plot(history.history['acc'])  \n",
    "    plt.plot(history.history['val_acc'])  \n",
    "    plt.title('model accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "\n",
    "    plt.subplot(222)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('model loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['train', 'valid']) \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df402136",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = (224, 224)\n",
    "x_train_reshaped, x_test_reshaped = list(map(lambda x: reshape_data(x, base_size), [x_train, x_test]))\n",
    "print(f'x_train_reshaped: {x_train_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f0ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(x_train_reshaped)\n",
    "\n",
    "vgg16_base_model = VGG16(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = input_shape\n",
    ")\n",
    "\n",
    "for layer in vgg16_base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "outputs = vgg16_base_model.output\n",
    "outputs = GlobalAveragePooling2D()(outputs)\n",
    "\n",
    "outputs = Dense(1024, activation='relu')(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "\n",
    "outputs = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "\n",
    "outputs = Dense(256, activation='relu')(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "vgg16_model = Model(vgg16_base_model.input, outputs)\n",
    "vgg16_model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.00001),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "vgg16_model_history = vgg16_model.fit(\n",
    "    x_train_reshaped, \n",
    "    y_train, \n",
    "    validation_data = (x_test_reshaped, y_test), \n",
    "    epochs = 50,\n",
    "    #steps_per_epoch = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f98029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Plot the Accuracy and Loss Curves\n",
    "plot_model_history(vgg16_model_history)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = vgg16_model.predict(x_test_reshaped)\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeec496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab386857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_size = (150, 150)\n",
    "x_train_reshaped, x_test_reshaped = list(map(lambda x: reshape_data(x, base_size), [x_train, x_test]))\n",
    "print(f'x_train_reshaped: {x_train_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7d569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(x_train_reshaped)\n",
    "inception_base_model = InceptionV3(\n",
    "    include_top = False,\n",
    "    input_shape = input_shape, \n",
    "    weights = 'imagenet'\n",
    ")\n",
    "\n",
    "for layer in inception_base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "outputs = Flatten()(inception_base_model.output)\n",
    "outputs = Dense(1024, activation='relu')(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "inception_model = Model(inception_base_model.input, outputs)\n",
    "\n",
    "inception_model.compile(\n",
    "    optimizer = RMSprop(learning_rate = 0.0001), \n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['acc']\n",
    ")\n",
    "inception_model_history = inception_model.fit(\n",
    "    x_train_reshaped, \n",
    "    y_train, \n",
    "    validation_data = (x_test_reshaped, y_test), \n",
    "    epochs = 100,\n",
    "    # steps_per_epoch = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a4ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot accuracy and loss\n",
    "plot_model_history(inception_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28165494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "y_pred =  np.round(inception_model.predict(x_test_reshaped))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n",
    "sns.heatmap(cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6933fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = (180, 180)\n",
    "x_train_reshaped, x_test_reshaped = list(map(lambda x: reshape_data(x, base_size), [x_train, x_test]))\n",
    "print(f'x_train_reshaped: {x_train_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5606530",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_shape = get_input_shape(x_train_reshaped)\n",
    "resnet50_base_model = ResNet50(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg',\n",
    "    classes = 2\n",
    ")\n",
    "\n",
    "for model_layer in resnet50_base_model.layers:\n",
    "    model_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef253a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnet50_model.compile(\n",
    "#     optimizer=\"Adam\", \n",
    "#     loss=\"binary_crossentropy\", \n",
    "#     metrics=[\"acc\"]\n",
    "# )\n",
    "\n",
    "# resnet50_model_history = resnet50_model.fit(\n",
    "#     x_train_reshaped, \n",
    "#     y_train, \n",
    "#     validation_data = (x_test_reshaped, y_test), \n",
    "#     epochs=10\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
